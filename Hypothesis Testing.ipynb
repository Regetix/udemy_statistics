{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b1a4b8-a4bd-4a3e-81b7-26eb6b3dade6",
   "metadata": {},
   "source": [
    "# Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6421f1f5-9a83-4c8a-af60-7fb028a12ccf",
   "metadata": {},
   "source": [
    "In order to provde or disprove anything first we need a hypothesis. First we have to set a Null Hypothesis which is the exacty contrary to the experiment expectation. For example we want to test Drugs A is good for health. There are three outcomes of consuming drug A:\n",
    "1. Positive effect: Which increases the overall health\n",
    "2. Neutral: Doesn't improve or degrade the overall health\n",
    "3. Negative: Disimproves the overall health.\n",
    "\n",
    "Since we have no clue which one of them might be, we have to test whether if it has any effect or not. So:\n",
    "- Null hypothesis(H0) will be: *Drug A has no effect on overall health*\n",
    "- Alternative hypothesis (H1): *Drug A affects the overall health*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765f9249-6cc8-4991-b853-d4e81a09843b",
   "metadata": {},
   "source": [
    "| Null hypothesis (H0) | Alternative hypothesis(H1) |\n",
    "| -------------------- | -------------------------- |\n",
    "| $A=B$| $A>B$ |\n",
    "| $A\\le B$ | $A<B$ |\n",
    "| $A\\ge B$ |       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304486bf-1e4a-45d1-9485-2ed6cb842504",
   "metadata": {},
   "source": [
    "To prove our expected outcome we must first reject the Null Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e923d3-616a-4a31-b3d3-ab3669d58df6",
   "metadata": {},
   "source": [
    "# Significance level "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf367f3-591c-478c-9a15-515a41d3d371",
   "metadata": {},
   "source": [
    "First let's talk about the errors. We have two types of error while making hypothesis:\n",
    "- Type I: When you reject H_0 but in reality H_0 is true\n",
    "- Type II: When you accept H_0 but in reality H_0 is false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000cb5fa-6ee7-4f35-a811-6b5921fdff04",
   "metadata": {},
   "source": [
    "| Reality \\ Conclusion | Accept H_0 | Refuse H_0 |\n",
    "| -------------------- | ---------- | ---------- |\n",
    "| H_0 is really true | Correct conlusion | Type I error |\n",
    "| H_0 is really false | Type II error | Correct conclusion |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2b9ecc-f2f1-475c-b0cf-52bb44229333",
   "metadata": {},
   "source": [
    "For example: Imagine it as a mariatal discussion or an arguement. Type I error is when the man is write but wife refuses to acknowledge that. Type II error is when man is wrong and the woman is wrong so wife is right and man made a Type II error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dbe77f-0764-4064-b30f-265cc528c52b",
   "metadata": {},
   "source": [
    "The probability of commiting a Type I error in statistical hypothesis testing is called alpha. In scientific papers, it is usually set a 0.05 which means the chance commiting a type I error is 5%\n",
    "Hence: $$ \\alpha = 0.05 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c82180-4dee-40ee-9d37-cf2a115a2ee2",
   "metadata": {},
   "source": [
    "### P-value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cfb266-89d7-44fc-b7b2-aee0d22a545f",
   "metadata": {},
   "source": [
    "A p-value represents the probability of obtaining results as extreme as, or more extreme than, the results observed in a statistical test, assuming the null hypothesis is true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f79d82-2f04-48ff-aa44-13104f68ad24",
   "metadata": {},
   "source": [
    "‚Ä¢ Key Point:  It doesn't tell you the probability that the null hypothesis is true.  It‚Äôs a crucial distinction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da8cd84-d67d-4ba3-a1b7-aded02b04b11",
   "metadata": {},
   "source": [
    "‚Ä¢ Small p-value (typically ‚â§ 0.05): This means that if the null hypothesis were true, there‚Äôs a low probability of observing the data you saw.  Because of this low probability, you *reject* the null hypothesis. You conclude that there‚Äôs enough evidence to suggest the null hypothesis is likely false.  This leads you to accept the alternative hypothesis.\n",
    "\n",
    "‚Ä¢ Large p-value (typically > 0.05):  This means that if the null hypothesis is true, it's *plausible* to observe the data you saw.  You *fail to reject* the null hypothesis.  This doesn't mean the null hypothesis is true ‚Äì it just means you don't have enough evidence to disprove it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b17b84-3b4c-4d1e-9679-16bfc6602e43",
   "metadata": {},
   "source": [
    "Let‚Äôs say you're testing whether a new teaching method improves student test scores.\n",
    "\n",
    "‚Ä¢ H‚ÇÄ: The new teaching method has no effect on test scores.\n",
    "You conduct an experiment and find that students taught with the new method score significantly higher than those taught with the traditional method. </br>\n",
    "‚Ä¢ P-value = 0.03: This means that if the new teaching method actually had **no** effect, there's only a 3% chance of observing a difference in test scores as large as the one you saw.  Since 0.03 is less than the Œ± level (usually 0.05), you reject the null hypothesis and conclude that the new teaching method **does** have a significant positive effect. The logic behind it is when with the assumption,the chance of what you've seen has happened is low, then the assumption should be false."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bf8e10-d714-47fc-b58a-a34fde4eb185",
   "metadata": {},
   "source": [
    "# Test Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8253f58-6b27-4250-80da-ef4cfc214d02",
   "metadata": {},
   "source": [
    "**Definition**: A test statistic is a numerical value calculated from your sample data that‚Äôs used to assess how different your sample data is from what you‚Äôd expect to see if the null hypothesis were true.  It‚Äôs essentially a standardized measure of the difference between your sample data and the population parameter you‚Äôre trying to estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bd0299-3fd2-4cd4-9120-c47f15b96a80",
   "metadata": {},
   "source": [
    "Think of it as:  A single number that summarizes the evidence from your data in relation to the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67dba97-c012-4b7b-8cb6-75ead106ee4c",
   "metadata": {},
   "source": [
    "Why Use a Test Statistic?\n",
    "- Standardization:  Different datasets have different scales and variances. A test statistic allows you to compare results across different studies, even if the data isn't on the same scale.\n",
    "- Relationship to the Null Hypothesis: The test statistic allows you to determine how likely your observed data is *if* the null hypothesis were true.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561d1296-6b47-40fb-af88-08dfaa0d7024",
   "metadata": {},
   "source": [
    "### Z-value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c18ef8f-6a1b-4075-87da-9f44644d9b3f",
   "metadata": {},
   "source": [
    "**z-statistic**: Used for large sample sizes (typically n > 30) when the population standard deviation is known. It measures the difference between the sample mean and the population mean, standardized by the population standard deviation. \n",
    "When we test a hypothesis using a z-value, we need to use the standard normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f543aec2-530b-4849-9c51-eef7a1ce1de2",
   "metadata": {},
   "source": [
    "for example: Z-value of a sample mean\n",
    "$$\\Huge {z = \\frac{\\bar{x} - \\mu}{\\sqrt{\\frac{\\sigma^2}{n}}}}$$\n",
    "Where:\n",
    "- $\\bar x$ is **sample mean**\n",
    "- $\\mu$ is Population mean\n",
    "- $\\sigma^2$ is Population variance\n",
    "- $n$ is sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551c4e9-be21-400e-948d-16a20cd2f1c2",
   "metadata": {},
   "source": [
    "Example: You want to test if the average height of women is 5‚Äô4‚Äù (64 inches). You take a sample of 25 women and find the sample mean height to be 63.5 inches with a sample standard deviation of 3 inches.\n",
    "t = (63.5 - 64) / (3 / ‚àö25)  = -0.5 / 1.2 = -0.4167"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076d0457-9086-4dd9-a128-96789643e231",
   "metadata": {},
   "source": [
    "### T-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a4de5d-045d-4ef8-82c7-3ff6b7c15ba5",
   "metadata": {},
   "source": [
    "When the sample size is n and not larg enough (n<=30), the t-value follows a t-distribuition with a degree of freedom euqals to \"N-1\".</br>\n",
    "$$\\Huge {t= \\frac{\\bar x - \\mu}{\\sqrt{\\frac{s^2}{n}}}}$$\n",
    "Where:\n",
    "- $\\bar x$ is the sample mean.\n",
    "- $\\mu$ is population mean\n",
    "- $\\sigma^2$ unbiased devitaion\n",
    "- $n$ is the sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b34fbf-7f05-4770-ba6d-1c10ace558cf",
   "metadata": {},
   "source": [
    "#### Unbiased variance $\\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4678667-9c5d-4812-8e18-764a13409006",
   "metadata": {},
   "source": [
    "When you are not aware of the population variance, you can instead use the unbiased variance. To calculate it:\n",
    "$$\\Huge s^2= \\frac {\\sum_{i=1}^{n}{(x_i- \\bar x)}}{n-1}$$\n",
    "Basically it's the variance but instead of dividing it by n, use n-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03ee11e-5789-486c-8ce3-3511733ddfa3",
   "metadata": {},
   "source": [
    "We two types of testing:\n",
    "- One tailed test: In simple terms you want to test whether A is bigger or smaller than B. For example: You want to test the IQ between women(B) and men(A). Your alternate hypothesis is men have higher IQ than women. So the H_0 will be Men have less or equal IQ score compared to women. In math termsL: $H_0 = A \\le B$ and $H_1 = A > B$ or vice versa\n",
    "- Two tailed test: When you are not sure about the the significance of the difference regardless of the direction. For example: You are not sure men IQ is different than women. You assume (H_1) Men have difference IQ average than women. So your H_0 is Men and Women mean IQ are the same. in math terms: $H_0: A=B $ and $H_1: A\\neq B$\n",
    "![one vs two tailed test](https://codefinity-content-media.s3.eu-west-1.amazonaws.com/a849660e-ddfa-4033-80a6-94a1b7772e23/Testing2.0/CriticalRegion.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7caec106-720e-48f5-9e92-2afff8aeb914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_test answer is -11.06797181058933 and Critical level is -2.2621571628540997 Significance is: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(-11.06797181058933)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "#Sample mean\n",
    "x_bar= 2.3\n",
    "#Sample size\n",
    "n=10\n",
    "#Unbiased Variance\n",
    "s_2=0.16\n",
    "#Population mean\n",
    "mu=3.7\n",
    "#p-value\n",
    "alpha=0.05\n",
    "\n",
    "def two_tailed_t_test(sample_mean, sample_size, unbiased_var, pop_mean, alpha,log=True):\n",
    "    t_test= (sample_mean - pop_mean)/np.sqrt(unbiased_var/sample_size)\n",
    "    #Critical value calculation\n",
    "    t_val= stats.t.ppf(alpha/2,sample_size-1)\n",
    "    sig:bool = np.abs(t_test) > np.abs(t_val)\n",
    "    if (log): print(f'T_test answer is {t_test} and Critical level is {t_val} Significance is: {sig}')\n",
    "    return t_test\n",
    "\n",
    "two_tailed_t_test(x_bar,n,s_2,mu,alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d65803c-34c4-47fe-981d-e815e1b7e7a2",
   "metadata": {},
   "source": [
    "## Dependant T_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ceeca5-d52a-4aae-8fb5-d08dc4bbce54",
   "metadata": {},
   "source": [
    "It's referred to a t_test performed on two data gathered from the same sample. Mostly in a before after scenario. For example in a Case-control experiment when you want to see the effects of a drug on something, you usually evaluate the sample before and after the drug usage. If you want to see the effect of a new SSRI drug on anxiety, first you give them a questionnaire before giving them the drug. Then you give them the drug. After the period has passed, you evaluate them again by giving them the same questionnaire to answer. Then you compare the before and after mean score. H_0 says: **No difference should be seen in mean of each outcomes**. In other words, The mean difference between before and after of the same sample must be zero. To reject the null hypothesis you need to do a **Dependant t_test**. </br>\n",
    "Let's be more specific. Suppose you have a sample of 30 people. You want to test if Fluxetine (an anxiolytic drug) can influence anxietyin any way in human(reduction or increase) . After u have gathered their info and also gathered another group of 30 people as control (getting placebo), you give them the [GAD-7](https://adaa.org/sites/default/files/GAD-7_Anxiety-updated_0.pdf) questionnaire before drug usage. Their score vary from 1 to 21.\n",
    "$$\\Huge t = \\frac {(\\bar x_1 - \\bar x_2)-(\\mu_1 - \\mu_2)} {\\sqrt{s^2(\\frac{1}{n_1}+\\frac{1}{n_2})}}=  \\frac{\\bar{x}_1 - \\bar{x}_2}{s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}$$\n",
    "where:\n",
    "- $s_p$ is the unbiased standard deviation\n",
    "- $x_1$ is the before group (Mean)\n",
    "- $x_2$ is the after group (Mean)\n",
    "- $\\mu_1$ and $\\mu_2$ are the population mean and since the population is the same, mean difference should be 0\n",
    "- $s^2$ is the unbiased variance\n",
    "- $n_i$ is the sample size\n",
    "- **Note**: It doesn't matter much which one you put as before and after. It just makes it negative or positive which at the end we are gonna use the abstract function. So, it doesn't matter much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f08c12c9-d271-45c8-beb5-743c9ae937db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.085057471264385\n",
      "T_test answer is 1.1239451198907913 and Critical level is -2.0452296421327034 Significance is: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(1.1239451198907913)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependant_group_before = np.random.randint(1,22,30)\n",
    "dependant_group_after = np.random.randint(1,17,30)\n",
    "\n",
    "# Sample mean\n",
    "mean_before = dependant_group_before.mean()\n",
    "mean_after = dependant_group_after.mean()\n",
    "# Mean difference\n",
    "x_bar = mean_before - mean_after\n",
    "# Population mean\n",
    "# Based on null hypothesis Population mean must be zero (Cause it assumes no difference between two phases)\n",
    "mu = 0\n",
    "# Unbiased Variance \n",
    "# We used the unbiased because we are unaware of the population variance\n",
    "mean_diff_individual= dependant_group_before - dependant_group_after\n",
    "# ddof or \"Delta Degree of Freedom\" is the base of the fraction. In the equation it means N-ddof where N is the sample size.\n",
    "# Degree of freedom = N (sample size) - Delta (ddof)\n",
    "# To calculate the unbiased variance you need to divide the sum by N-ddof which is N-1.\n",
    "# So ddof would be 1\n",
    "s_2 = np.std(mean_diff_individual,ddof=1)**2\n",
    "print(s_2)\n",
    "#Sample size\n",
    "n= dependant_group_after.size\n",
    "# Alpha\n",
    "alpha= 0.05\n",
    "\n",
    "two_tailed_t_test(x_bar,n,s_2,mu,alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e970dee-6ac8-4a9f-918d-47e4266537e2",
   "metadata": {},
   "source": [
    "Alternatively, you can use *scipy* module to calculate all that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30a730f9-7255-45fa-ac74-cf240f4510a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=np.float64(-0.0834700301651629), pvalue=np.float64(0.9340513291429057), df=np.int64(29))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_rel(dependant_group_before,dependant_group_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3564d614-95b0-4165-80a7-7ef898408fe3",
   "metadata": {},
   "source": [
    "## Independant sample t_test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716cb636-0836-4333-8835-8ea18efefbe6",
   "metadata": {},
   "source": [
    "When you are gathering two seperate samples and evaulation them, it's called Independant. The result of the experiment in each group doesn't depend on the other one. Imagine something like this: You want to see whether Drug A or Drug B has better effect on an outcome. you picked two samples and assigned them randomly to each study group. Again the H_0 implies that difference of mean scores (by whatever measurement you evaluated) would be zero and you would see no difference between average of these two groups. To reject the null hypothesis, abstract of the  final t_test  number should be above the abstract of critical level. </br>\n",
    "**IMPORTANT: In the equation below we assumed the population variance is the same.** Like when you pick two samples from the same population\n",
    "$$\\Huge T = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14913ec-9067-40ee-9b54-6e1ab6baede9",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "- T: The calculated t-statistic.\n",
    "- $\\bar{x}_1$: The sample mean of group 1.\n",
    "- $\\bar{x}_2$: The sample mean of group 2.\n",
    "- $s_1$: The sample standard deviation of group 1.\n",
    "- $s_2$: The sample standard deviation of group 2.\n",
    "- $n_1$: The sample size of group 1.\n",
    "- $n_2$: The sample size of group 2.\n",
    "- **Note**: The reason which no *Population mean* is present in this equation is the population is mutual between these two sample. So the difference would be 0. $(\\mu - \\mu) =0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1962acd7-a628-430a-9044-e8817a07562b",
   "metadata": {},
   "source": [
    "There's another form for the dependant formula:\n",
    "$$\\Huge T = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{s^2(\\frac{1}{n_1} + \\frac{1}{n_2})}}$$\n",
    "But $s^2$ must be calculated this way:\n",
    "$$\\Huge s^2= \\frac {(n_1-1)\\times s_1^2 + (n_2-1)\\times s_2^2}{n_1+n_2-2}$$\n",
    "I personally prefer the former equation since it's simpler to remember and makes sense but they are both the same and also give you the same answer (Suprisingly!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c187aad-ce27-4d49-adc8-9642bf25a58a",
   "metadata": {},
   "source": [
    "**Example**: Imagine we want to compare the efficacy of Drug A and Drug B. We choose two samples with each having 30 sample size. All belong to the same population. We score them on a scale of 1 to 10 after the the drugs consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "73f0865f-03d8-4682-8b65-faa7a85756d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.86896551724138\n",
      "The T-test: -0.3197384359911364 and the Critical value is: -2.0452296421327034. Is it significant? False\n"
     ]
    }
   ],
   "source": [
    "independent_A = np.random.randint(1,10,30)\n",
    "independent_B = np.random.randint(1,10,30)\n",
    "\n",
    "# Sample mean\n",
    "mean_A = independent_A.mean()\n",
    "mean_B = independent_B.mean()\n",
    "# Unbiased sample Variance\n",
    "s2_A = np.var(independent_A, ddof=1)\n",
    "s2_B = np.var(independent_B, ddof=1)\n",
    "# Sample sizes\n",
    "n_A= independent_A.size\n",
    "n_B = independent_B.size\n",
    "\n",
    "def unbiased_var(sample_size1,sample_size2, var_1, var_2,log=True):\n",
    "    mul_1 = (sample_size1-1)*var_1\n",
    "    mul_2 = (sample_size2-1)*var_2\n",
    "    bottom= sample_size1+sample_size2-2\n",
    "    u_var = (mul_1 + mul_2)/bottom\n",
    "    if(log): print(u_var)\n",
    "    return u_var\n",
    "\n",
    "def t_test_ind(sample_mean1, sample_mean2,sample_size1,sample_size2, u_var,alpha=0.05,log=True):\n",
    "    mean_diff = sample_mean1 - sample_mean2\n",
    "    frac1= u_var / sample_size1\n",
    "    frac2= u_var / sample_size2\n",
    "    t_test= mean_diff / np.sqrt(frac1+frac2)\n",
    "    crit_val = stats.t.ppf(alpha/2,sample_size1-1)\n",
    "    is_sig= np.abs(t_test) > np.abs(crit_val)\n",
    "    if(log): print(f'The T-test: {t_test} and the Critical value is: {crit_val}. Is it significant? {is_sig}')\n",
    "    return t_test\n",
    "\n",
    "unbiased_var = unbiased_var(n_A,n_B,s2_A,s2_B)\n",
    "_ = t_test_ind(mean_A,mean_B,n_A,n_B,unbiased_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d874334b-cf34-43b6-a272-4b19600eba89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=np.float64(-0.3197384359911364), pvalue=np.float64(0.7503155337275975), df=np.float64(58.0))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(independent_A,independent_B,equal_var=True,nan_policy='propagate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38deb75-c8fe-486e-bdc9-1f2a3b458252",
   "metadata": {},
   "source": [
    "### Welch's Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d63b2f7-2335-48f3-99e5-e6f54bd38219",
   "metadata": {},
   "source": [
    "As mentioned Independant T_test formula assumed both samples were taken from the same population but that's not the case. For example you want to test if drug A has more effect on women or men. So you have two population: Men, Women. Sample 1 is a group consist of 30 men and Sample 2 is a group consist of 30 women. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa587bb0-796e-4b94-b11b-f935ab56626d",
   "metadata": {},
   "source": [
    "$$\\Huge t = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}$$\n",
    "To calculate the degree of freedom:\n",
    "$$\\Huge df(\\nu) = \\frac{\\left( \\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2} \\right)^2}\n",
    "{\\frac{\\left( \\frac{s_1^2}{n_1} \\right)^2}{n_1 - 1} + \\frac{\\left( \\frac{s_2^2}{n_2} \\right)^2}{n_2 - 1}} = \\frac{ (\\frac{s_1^2}{n_1}+ \\frac{s_2^2}{n_2})^2} { \\frac{s_1^4}{n_1^2(n_1-1)} + \\frac{s_2^4}{n_2^2(n_2-1)} }$$\n",
    "Where:\n",
    "- $df (\\nu)$ (the greek symbol is called nu) is the Degree of freedom\n",
    "- $\\bar X_1$, $\\bar X_2$ are sample means\n",
    "- $s_2^2$, $s_1^2$ are sample variances\n",
    "- $n_1$, $n_2$ are sample sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d285bc0-c71a-4d22-afb4-7eadad0f8585",
   "metadata": {},
   "source": [
    "### Degree of Freedom (DoF)\n",
    "\n",
    "In statistics, degrees of freedom (df) refer to the number of independent values or quantities that can vary in a statistical calculation without violating any constraints. Degrees of freedom are the number of values in the final calculation of a statistic that are free to vary. In simple terms: Think of degrees of freedom as the number of independent directions you can move in a system before you hit a constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea772f-f32f-44a1-b2f0-5102140024b1",
   "metadata": {},
   "source": [
    "üìä Example (Sample Variance):\n",
    "\n",
    "- Suppose you have a sample of 5 numbers, and you know their mean.\n",
    "- Here, one constraint exists: all data points must average to xÀâxÀâ. Once you know the first 4 numbers and the mean, the 5th number is fixed ‚Äî it cannot vary independently.\n",
    "\n",
    "‚úÖ So, for a sample of size n, only n‚àí1 data points can **freely vary**.\n",
    "üéØ Thus, degrees of freedom =n‚àí1 </br>\n",
    "In different contexts, Degree of freedom is calculated like below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b22a29-fbf3-49a9-99f2-d0f0626e223e",
   "metadata": {},
   "source": [
    "| **Context**             | **Degrees of Freedom (df)**                             |\n",
    "| ----------------------- | ------------------------------------------------------- |\n",
    "| **Sample Variance**     | $n - 1$ (due to using sample mean)                      |\n",
    "| **Two-sample t-test**   | Calculated using a formula (like Welch's approximation) |\n",
    "| **Chi-squared test**    | $(r - 1)(c - 1)$ for contingency tables                 |\n",
    "| **Regression analysis** | $n - k$ where $k$ = number of parameters estimated      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e67a79-8deb-4950-8d34-4db737a2ad81",
   "metadata": {},
   "source": [
    "Now let's examine independent T_test with an exmaple. Imagine you want to test a soup. You would like to see whether it really clears Women's skin or men's skin better. We score the hand hygiene after the washing in each group on a scale of 1 to 10. We want to compare if women hands are much cleaner or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7530c9d6-1903-4f8d-bb3e-f33cefef240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction 1: 0.19804597701149426 and Fraction 2 0.28812260536398465\n",
      "56.07504708747355\n",
      "The T-test: 1.3863832355612284 and the Critical value is: -2.0452296421327034. Is it significant? False\n"
     ]
    }
   ],
   "source": [
    "independent_W = np.random.randint(1,10,30)\n",
    "independent_M = np.random.randint(1,10, 30)\n",
    "\n",
    "# Sample mean\n",
    "mean_W = independent_W.mean()\n",
    "mean_M = independent_M.mean()\n",
    "# Unbiased sample Variance\n",
    "s2_W = np.var(independent_W, ddof=1)\n",
    "s2_M = np.var(independent_M, ddof=1)\n",
    "# Sample sizes\n",
    "n_W = independent_W.size\n",
    "n_M = independent_M.size\n",
    "\n",
    "def DOF_calc(sample_size1,sample_size2, var_1, var_2,log=True):\n",
    "    frac1= var_1/sample_size1\n",
    "    frac2= var_2/sample_size2\n",
    "    print(f'Fraction 1: {frac1} and Fraction 2 {frac2}')\n",
    "    bottom_frac1 = frac1/(sample_size1-1)\n",
    "    bottom_frac2 = frac2/(sample_size2-1)\n",
    "    top = np.power(frac1+frac2, 2)\n",
    "    bottom_1= np.power(frac1,2)/(sample_size1-1)\n",
    "    bottom_2= np.power(frac2,2)/(sample_size2-1)\n",
    "    bottom = bottom_1 + bottom_2\n",
    "    final_df = top/bottom\n",
    "    if(log): print(final_df)\n",
    "    return final_df\n",
    "\n",
    "def welch_test_ind(sample_mean1, sample_mean2,sample_size1,sample_size2, var_1, var_2,alpha=0.05,log=True):\n",
    "    mean_diff = sample_mean1 - sample_mean2\n",
    "    frac1= var_1 / sample_size1\n",
    "    frac2= var_2 / sample_size2\n",
    "    t_test= mean_diff / np.sqrt(frac1+frac2)\n",
    "    crit_val = stats.t.ppf(alpha/2,sample_size1-1)\n",
    "    is_sig= np.abs(t_test) > np.abs(crit_val)\n",
    "    if(log): print(f'The T-test: {t_test} and the Critical value is: {crit_val}. Is it significant? {is_sig}')\n",
    "    return t_test\n",
    "\n",
    "_ = DOF_calc(n_W,n_M,s2_W,s2_M)\n",
    "_ = welch_test_ind(mean_W,mean_M,n_W,n_M,s2_W,s2_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9bbb497d-cfc4-4398-bd77-f3507bcb058b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=np.float64(1.3863832355612282), pvalue=np.float64(0.17111775459270312), df=np.float64(56.07504708747357))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(independent_W,independent_M,equal_var=False,nan_policy='propagate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dd5e8c-13e7-4fd3-980c-361a5b2cffec",
   "metadata": {},
   "source": [
    "# Proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d43570-b028-4597-bc74-9d498601f343",
   "metadata": {},
   "source": [
    "We have two types of proportions:\n",
    "1. Sample proportion\n",
    "2. Population proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9b12db-6cea-41ed-9a8c-b44650c90199",
   "metadata": {},
   "source": [
    "## Population proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac413da4-bd2d-4334-9cc2-e154c2dfbd74",
   "metadata": {},
   "source": [
    "It means a subset of the whole population which has a specific charactersitic. For example: If a city has 1000 citizens and 300 of them have electrical cars, we can say the population proportion of electrical car owners are 30% of the total population. It's written like this:\n",
    "$$ P= \\frac X N$$\n",
    "Where:\n",
    "- $P$ is the population proportion\n",
    "- $X$ is the number of individuals in the population with the characteristic\n",
    "- $N$ is the total number of individuals in the population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdb0813-7735-4eaa-bcd3-44232e5470f2",
   "metadata": {},
   "source": [
    "## Sample proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99488ebf-81bc-468a-a45b-7977f8369a9e",
   "metadata": {},
   "source": [
    "The estimated proportion of individuals with the characteristic based on a **sample** taken from the population. So, it's a fraction of the sample not the main population.\n",
    "$$\\hat p = \\frac x n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b3d34a-75eb-4a44-8eed-764cdc33f165",
   "metadata": {},
   "source": [
    "| Feature            | Population Proportion (P)       | Sample Proportion ($\\hat{p}$)         |\n",
    "| ------------------ | ------------------------------- | ------------------------------------- |\n",
    "| Represents         | Whole population                | A subset/sample of the population     |\n",
    "| Known or estimated | Usually unknown                 | Calculated from sample data           |\n",
    "| Purpose            | True value we aim to understand | Estimate of the true population value |\n",
    "| Example            | % of **all** citizens who vote  | % of **surveyed** citizens who vote   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3953b984-32e4-4ed9-a53b-70f7997d4703",
   "metadata": {},
   "source": [
    "# Goodness of fit test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f76dde-8d1e-421f-9186-e007b77de4bc",
   "metadata": {},
   "source": [
    "Suppose you have a sample but it's unclear whether this sample follows the population distrubution or not. Basically, it tests whether the sample is repesentative of the original population or not. It's usually test by **Chi-square test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3129d3ca-057d-4773-bd20-1a093249e4b1",
   "metadata": {},
   "source": [
    "## Chi-square test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62bd547-81ff-41b8-93dc-82176c7d3a1c",
   "metadata": {},
   "source": [
    "The Chi-square test compares observed frequencies (actual counts) with expected frequencies (what we would expect if there were no relationship or difference)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7151bf82-baa0-4de1-a2fc-e2b23b1a391c",
   "metadata": {},
   "source": [
    "We have two different types of chi-square tests mentioned in the table below:\n",
    "| Test Type                                  | Purpose                                                                         |\n",
    "| ------------------------------------------ | ------------------------------------------------------------------------------- |\n",
    "| **1. Chi-Square Test for Goodness of Fit** | Tests whether a single categorical variable matches a hypothesized distribution |\n",
    "| **2. Chi-Square Test for Independence**    | Tests whether **two categorical variables** are **related or independent**      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f4f302-6aca-4e71-b019-15d5aa071e21",
   "metadata": {},
   "source": [
    "> **USE CASE**: When you have one categorical variable and want to see if it follows a specific distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01320ecb-5a0e-4973-a0a9-9501ab8745cc",
   "metadata": {},
   "source": [
    "$$\\Large x^2 = \\sum_{i=1}^n {\\frac{(O_i - E_i)^2}{E_i}}$$\n",
    "where:\n",
    "- $O_i$ is the Observed frequency\n",
    "- $E_i$ is the Expected frequency\n",
    "- $n$ is the number of possible combinations\n",
    "\n",
    "You compare the chi-square statistic to a critical value from the chi-square distribution table, based on degrees of freedom(df).\n",
    "$df= \\text{number of categories} -1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e2b029-4b65-4c56-b4b5-a1f801851f0b",
   "metadata": {},
   "source": [
    "### Expected Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1ecc71-dbde-4fbb-8d1c-b6c8d9c6dd63",
   "metadata": {},
   "source": [
    "This one is pretty tricky so bear with me. Expected frequency is the number of observations we would expect in each category or cell if the null hypothesis were true (i.e., if there were no association or no difference).Pretty obvious right? but the formula is confusing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c0a749-37f9-4e74-b08d-7d7ef85618f3",
   "metadata": {},
   "source": [
    "The equation is:\n",
    "$$\\Large E_{ij}=\\frac{R \\text{(Row total} \\times C \\text{(Column total)}}{G \\text{(Grand total)}}$$\n",
    "Where:\n",
    "- $E_{ij}$ is the expected frequency for the cell in row i, column j\n",
    "- Row Total = total number of observations in that row\n",
    "- Column Total = total number of observations in that column\n",
    "- Grand Total = total number of all observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a4a39d-2827-46cc-a920-3e80bd9a6001",
   "metadata": {},
   "source": [
    "Let's see it in practice. Imagine this table of observed data:\n",
    "|           | Tea | Coffee | **Total** |\n",
    "| --------- | --- | ------ | --------- |\n",
    "| Men       | 20  | 30     | 50        |\n",
    "| Women     | 30  | 20     | 50        |\n",
    "| **Total** | 50  | 50     | 100       |\n",
    "\n",
    "Let‚Äôs calculate the expected frequency for Men & Tea:\n",
    "$$ E = \\frac{50 \\times 50}{100} = 25$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d29f51e-7f61-4037-bee0-aea3b872462a",
   "metadata": {},
   "source": [
    "You can calculate this for every combination like:\n",
    "Expected Men-Tea = $ E = \\frac{50 \\times 50}{100} = 25$ </br>\n",
    "Expected Men-Coffee = $ E = \\frac{50 \\times 50}{100} = 25$</br>\n",
    "Expected Women-Tea = $ E = \\frac{50 \\times 50}{100} = 25$</br>\n",
    "Expected Women-Coffee = $ E = \\frac{50 \\times 50}{100} = 25$</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122100b0-4443-4284-a774-0f3c7b2fda6c",
   "metadata": {},
   "source": [
    "So the expected table will be like this\n",
    "|       | Tea | Coffee | Total |\n",
    "| ----- | --- | ------ | ----- |\n",
    "| Men   | 25  | 25     | 50    |\n",
    "| Women | 25  | 25     | 50    |\n",
    "| Total | 50  | 50     | 100   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fd2f8f-65e4-4afe-808e-5a0c7a81b8ca",
   "metadata": {},
   "source": [
    "### Chi square test of independence example\n",
    "Now let's calculate the chi square test for this sample as well. We need a hypothesis: </br>\n",
    "Null hypothesis H_0: Gender and beverage preference are independent </br>\n",
    "Alternative hypothesis H_1: Gender and beverage preference are dependent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1039a3c4-153b-431e-99a5-3ca7e6617c13",
   "metadata": {},
   "source": [
    "For each case:\n",
    "- Men, tea: $$(20-25)^2 /25 = 1$$\n",
    "- Men, coffee: $$(30-25)^2/25=1$$\n",
    "- Women, tea: $$(30-25)^2/25=1$$\n",
    "- Women, coffee: $$(20-25)^2/25=1$$\n",
    "\n",
    "**Chi-sqaure statistic total:** $$x^2= 1+1+1+1=4$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c74c7e5-84d6-4c1a-b3d6-783d04e08861",
   "metadata": {},
   "source": [
    "**Degree of freedom**: $df=(r-1)(c-1)=(2-1)(2-1)=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792538e8-302d-4706-98fe-f4fbf7cd7910",
   "metadata": {},
   "source": [
    "At a significance level Œ±=0.05 and 1 degree of freedom, the critical value from the Chi-square table is: $$X_{critical}^2 = 3.841$$\n",
    "and 4 is more than this. So we **REJECT** null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf470aec-c03d-4082-aad2-e252edcc4cae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For each axis slice, the sum of the observed frequencies must agree with the sum of the expected frequencies to a relative tolerance of 1.4901161193847656e-08, but the percent differences are:\n13.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_60923/3719101593.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Chi-square goodness of fit test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchisquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_obs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_exp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.13/site-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(f_obs, f_exp, ddof, axis, sum_check)\u001b[0m\n\u001b[1;32m   7502\u001b[0m     \u001b[0mPower_divergenceResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3.5\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m9.25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.62338763\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.09949846\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7504\u001b[0m     \u001b[0mFor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdetailed\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mhypothesis_chisquare\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7505\u001b[0m     \"\"\"  # noqa: E501\n\u001b[0;32m-> 7506\u001b[0;31m     return _power_divergence(f_obs, f_exp=f_exp, ddof=ddof, axis=axis,\n\u001b[0m\u001b[1;32m   7507\u001b[0m                              \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pearson\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.13/site-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(f_obs, f_exp, ddof, axis, lambda_, sum_check)\u001b[0m\n\u001b[1;32m   7318\u001b[0m                        \u001b[0;34mf\"\u001b[0m\u001b[0;34mfrequencies must agree with the sum of the \u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7319\u001b[0m                        \u001b[0;34mf\"\u001b[0m\u001b[0;34mexpected frequencies to a relative tolerance \u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7320\u001b[0m                        \u001b[0;34mf\"\u001b[0m\u001b[0;34mof \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m, but the percent differences are:\\n\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7321\u001b[0m                        \u001b[0;34mf\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mrelative_diff\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7322\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7324\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7325\u001b[0m         \u001b[0;31m# Ignore 'invalid' errors so the edge case of a data set with length 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: For each axis slice, the sum of the observed frequencies must agree with the sum of the expected frequencies to a relative tolerance of 1.4901161193847656e-08, but the percent differences are:\n13.0"
     ]
    }
   ],
   "source": [
    "# Goodness of fit test example\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Data\n",
    "sample=[40,30,30]\n",
    "population=[600,300,500]\n",
    "\n",
    "# Chi-square goodness of fit test\n",
    "stats.chisquare(f_obs=sample, f_exp=population)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6b007a-cb53-479d-ad44-7c295009bf27",
   "metadata": {},
   "source": [
    "I wrote the upper code intentionally just you could see the error. You see the Expected list which represents the population, the sum of the frequencies must match the sum of sample frequencies. for example I have 40 , 30 , 30 sample from each 600,300,500 populations respectively. I can't just give it to the fucntion because 40+30+30=100 but 600+300+500= 1400 which mismatches. In order to fix it you must first get the proportions of the total population then mutiple each proportion by the sample total. Checkout the below code to understand it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad484d2e-5bb4-448d-8147-7db43f01c7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=np.float64(4.533333333333335), pvalue=np.float64(0.10365712861152776))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Goodness of fit test example\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "# Data\n",
    "sample = np.array([40,30,30])\n",
    "population = np.array([600,300,500])\n",
    "\n",
    "total_sample= sample.sum()\n",
    "total_pop = population.sum()\n",
    "\n",
    "population = population / total_pop\n",
    "population = population * total_sample\n",
    "\n",
    "stats.chisquare(f_obs=sample, f_exp=population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca005cd-51f7-43f8-a069-ab9a951934ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
